{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#........Importing Required Libraries........#\n",
    "from io import BytesIO\n",
    "import json\n",
    "import pandas as pd\n",
    "import fitz\n",
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from typing_extensions import TypedDict\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Openai paid key\n",
    "openai.api_key = \"YOUR_API_KEY\" \n",
    "gpt_model = 'MODEL_NAME'  \n",
    "embedding_model = \"EMBEDDING_MOEL\"\n",
    "client = OpenAI(api_key = \"YOUR_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = \"\"\"Identify the specifications from the provided document context and extract the values for the identified specifications from the context. \n",
    "                      Provide the extracted specifications from the provided context in a structured JSON format. Each specification should have an value entry. \n",
    "                      The values should also include the associated units if available. If a specification is missing, include 'N/A' for that entry.\n",
    "                      The first two entires of the specification should be 'company' and 'product/Model Number'. Extract as many specifications as possible from the provided contexts.\n",
    "                      If the fetched values has any special characters like backslash etc., convert the values such that it will not create any issues while parsing the JSON. \n",
    "                      If the extracted value for any specification is in nested format, convert them into a list of key value pair and stick to the required format of JSON. Don't output in nested json format. Don't use same keys again and again, but instead merge similar key information into a list of strings.\n",
    "                      Format your response as: \n",
    "                      {\n",
    "                        \"company\": [\"Value from context1\"],\n",
    "                        \"product/Model Number\": [\"Value from context1\"],\n",
    "                        \"Specification 3\": [\"Value from context1\"], \n",
    "                        \"Specification 4\": [\"Value from context1\"], \n",
    "                        ... \n",
    "                      }\n",
    "                      \n",
    "                      \"\"\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from PDF file\n",
    "def extract_text_from_pdf(file) -> str:\n",
    "    pdf_reader = fitz.open(file)\n",
    "    full_text = \"\"\n",
    "    page_texts = []\n",
    "    # for page_num in range(pdf_reader.getNumPages()):\n",
    "    for page_num in range(pdf_reader.page_count):\n",
    "        page = pdf_reader[page_num]\n",
    "        text = page.get_text(\"text\") \n",
    "        blocks = page.get_text(\"blocks\")\n",
    "\n",
    "        processed_blocks = []\n",
    "        for b in blocks:\n",
    "            block_text = b[4].strip()\n",
    "            if block_text:\n",
    "                if \":\" in block_text:\n",
    "                    processed_blocks.append(block_text)\n",
    "                else:\n",
    "                    processed_blocks.append(block_text.replace(\"\\n\", \" \"))\n",
    "        processed_text = \"\\n\".join(processed_blocks)\n",
    "        full_text += processed_text + \"\\n\\n\"\n",
    "        page_texts.append(processed_text)\n",
    "        # st.session_state.pdf_text = page_texts\n",
    "    return page_texts\n",
    "\n",
    "\n",
    "#......Function to extract specs from the input datasheet text......#\n",
    "def extract_specs(pdf1_text: str, input_prompt: str) -> str:\n",
    "    text1 = pdf1_text\n",
    "    # text2 = pdf2_text\n",
    "    # .....Generating the responses using the two input contexts......#\n",
    "    response = client.chat.completions.create(\n",
    "        model=gpt_model, \n",
    "        messages = [ {\"role\": \"assistant\", \"content\": input_prompt\n",
    "                      },\n",
    "                      {\"role\": \"system\", \"content\": f\"context1: {text1}\"},\n",
    "                    #   {\"role\": \"user\", \"content\": query_text}\n",
    "                      ], #prompt=prompt_template,\n",
    "        max_tokens=1200,\n",
    "        temperature = 0.1,\n",
    "    )\n",
    "    specifications = response.choices[0].message.content\n",
    "    return specifications\n",
    "\n",
    "#.....Function to rewrite the input prompt......#\n",
    "def rewrite_query(input_prompt: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=gpt_model, \n",
    "        messages = [ {\"role\": \"assistant\", \"content\": \"\"\"You are a question re-writer that converts an input question to a better version that is optimized to fetch accurate answer from the input document. \n",
    "                      Look at the input and try to reason about the underlying semantic intent / meaning. Provide the response in a string format enclosed in thrible quotes.\n",
    "                      \n",
    "                      input question: {input_prompt}\n",
    "                      \"\"\"\n",
    "                      },\n",
    "                    #   {\"role\": \"system\", \"content\": f\"context1: {text1}\"},\n",
    "                    #   {\"role\": \"user\", \"content\": query_text}\n",
    "                      ], #prompt=prompt_template,\n",
    "        max_tokens=600,\n",
    "        temperature = 0.1,\n",
    "    )\n",
    "    rewrited_prompt = response.choices[0].message.content\n",
    "    return rewrited_prompt\n",
    "\n",
    "#..........Fetching additional information that seems to be missing from datasheet..........#\n",
    "def fetch_additional_info(specifications_list: list) -> str:\n",
    "    \n",
    "    #.....Defining the specifications to be extracted from the context.....#\n",
    "    company_name = specifications_list[0]\n",
    "    product_model = specifications_list[1]\n",
    "    missing_specs = specifications_list[2:]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=gpt_model, \n",
    "        messages = [ {\"role\": \"assistant\", \"content\": \"\"\"You are an expert in identified specifications when provided with Company Name and Product Model Number. Given a list of specifications to be extracted, you are required to use the given company name and model number and fetch the values for all the provided specifications. Inputs are:\n",
    "                      Company Name: {company_name}\n",
    "                      Model Number: {product_model}\n",
    "                      and the list of specifications to be extracted: {missing_specs}\n",
    "                      \n",
    "                      For all the specifications to be fetched provide the identified response in a structured JSON format. Each specification should have an value entry. \n",
    "                      The values should also include the associated units if available. If a specification is missing, include 'N/A' for that entry. For all the non-missing specs include the text '(from internet)' along with the values.\n",
    "                      If the fetched values has any special characters, convert the values such that it will not create any issues while parsing the JSON.\n",
    "\n",
    "                      Format your response as: \n",
    "                      {\n",
    "                        \"Specification 1\": [\"Value (from internet)\"], ..\n",
    "                        \"Specification 2\": [\"Value (from internet)\"],\n",
    "                        ... \n",
    "                      }\n",
    "                      \"\"\"\n",
    "                      },\n",
    "                      # {\"role\": \"system\", \"content\": f\"context1: {text1}\"},\n",
    "                      # {\"role\": \"user\", \"content\": query_text}\n",
    "                      ], #prompt=prompt_template,\n",
    "        max_tokens=1200,\n",
    "        temperature = 0.1,\n",
    "    )\n",
    "    specifications = response.choices[0].message.content\n",
    "    return specifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..........Functions to handle different user selections..........#\n",
    "#.....Function to handle situation when the user selects correct.....#\n",
    "def handle_correct_action(state):\n",
    "    return {\"filtered_specs\": state[\"specifications\"], \"additional_info\": None}\n",
    "    # return state\n",
    "\n",
    "#.....Function to handle situation when the user selects incomplete.....#\n",
    "def handle_incomplete_action(specs):\n",
    "    specifications = json.loads(specs)\n",
    "    keywords_list = [\"Display\", \"Battery\", \"Processor\", \"Memory\", \"Storage\", \"Operating System\", \"Price\", \"Weight\", \"Connectivity\", \"Guarantee\", \"Graphics\", \"Battery Life\", \"Material\", \"Refresh Rate\"]\n",
    "    # relevance_score = 0\n",
    "    missed_keywords = [\"company\", \"Model Number\"]  # Initialize missed keywords with company and product/model number\n",
    "    # threshold = 12  # Define a threshold for relevance\n",
    "    \n",
    "    # Get the list of keys from the extracted specifications\n",
    "    spec_keys = [key for key, value in specifications.items()]\n",
    "    \n",
    "    # Find the missed keywords\n",
    "    for keyword in keywords_list:\n",
    "        if keyword not in spec_keys:\n",
    "            missed_keywords.append(keyword) \n",
    "\n",
    "    # Find keys with value 'N/A'\n",
    "    keys_with_na = [key for key, value in specifications.items() if value == [\"N/A\"]]\n",
    "    # filtered_specs = {key: value for key, value in specifications.items() if value != [\"N/A\"]}\n",
    "\n",
    "    all_missed_keys = missed_keywords + keys_with_na\n",
    "    additional_info = fetch_additional_info(all_missed_keys)\n",
    "\n",
    "    return additional_info\n",
    "    # return state\n",
    "\n",
    "\n",
    "#.....Function to handle situation when the user selects incorrect.....#\n",
    "def handle_incorrect_action(pdf_text, input_prompt):\n",
    "    \n",
    "    # rewrited_prompt = rewrite_query(input_prompt)\n",
    "    # specifications = extract_specs(specs, rewrited_prompt)\n",
    "    specifications = extract_specs(pdf_text, input_prompt)\n",
    "    # print(\"Specs before loading\")\n",
    "    # print(specifications)\n",
    "\n",
    "    try:\n",
    "        # Convert JSON string to a Python dictionary\n",
    "        if isinstance(specifications, str):  # Ensure it's a string before parsing\n",
    "            spec_type = type(specifications)\n",
    "            specifications = json.loads(specifications)\n",
    "    except:\n",
    "        print(\"error in loading spec as json\")\n",
    "\n",
    "    # print(\"Specs after loading\")\n",
    "    # print(specifications)\n",
    "\n",
    "    # specifications = json.loads(specifications)\n",
    "    keywords_list = [\"Display\", \"Battery\", \"Processor\", \"Memory\", \"Storage\", \"Operating System\", \"Price\", \"Weight\", \"Connectivity\", \"Guarantee\", \"Graphics\", \"Battery Life\", \"Material\", \"Refresh Rate\"]\n",
    "    # relevance_score = 0\n",
    "    missed_keywords = [\"company\", \"Model Number\"]  # Initialize missed keywords with company and product/model number\n",
    "    \n",
    "    # Get the list of keys from the extracted specifications\n",
    "    spec_keys = [key for key, value in specifications.items()]\n",
    "    \n",
    "    # Find the missed keywords\n",
    "    for keyword in keywords_list:\n",
    "        if keyword not in spec_keys:\n",
    "            missed_keywords.append(keyword) \n",
    "\n",
    "    # Find keys with value 'N/A'\n",
    "    keys_with_na = [key for key, value in specifications.items() if value == [\"N/A\"]]\n",
    "    filtered_specs = {key: value for key, value in specifications.items() if value != [\"N/A\"]}\n",
    "\n",
    "    all_missed_keys = missed_keywords + keys_with_na\n",
    "    additional_info = fetch_additional_info(all_missed_keys)\n",
    "    print(\"type of additional_info: \", type(additional_info))\n",
    "\n",
    "    return filtered_specs, additional_info\n",
    "    # return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file_1 = r\"C:\\Users\\INBHV3\\OneDrive - ABB\\Bhanu Work Files\\Implementations\\Doc Comparison\\doc-comparison-main\\inputs\\Acer-Nitro5-specs.pdf\"\n",
    "# uploaded_file_2 = r\"C:\\Users\\INBHV3\\OneDrive - ABB\\Bhanu Work Files\\Implementations\\Doc Comparison\\doc-comparison-main\\inputs\\alienware-17-specs.pdf\"\n",
    "\n",
    "class State(TypedDict):\n",
    "    uploaded_file_1: bytes\n",
    "    pdf1_text: str\n",
    "    specifications: str\n",
    "\n",
    "#..........Create the graph..........#\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "#..........Define the nodes..........#\n",
    "graph_builder.add_node(\"extract_text_doc1\", lambda state: {\"pdf1_text\": extract_text_from_pdf(state[\"uploaded_file_1\"])})\n",
    "# graph_builder.add_node(\"extract_text_doc2\", lambda state: {\"pdf2_text\": extract_text_from_pdf(state[\"uploaded_file_2\"])})\n",
    "graph_builder.add_node(\"extract_specs\", lambda state: {\"specifications\": extract_specs(state[\"pdf1_text\"], input_prompt)})\n",
    "\n",
    "# Define the edges that connects the nodes\n",
    "graph_builder.add_edge(START, \"extract_text_doc1\")\n",
    "graph_builder.add_edge(\"extract_text_doc1\",\"extract_specs\")\n",
    "graph_builder.add_edge(\"extract_specs\", END)\n",
    "\n",
    "# Execute the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Assuming pdf1_file and pdf2_file are the uploaded PDF files in bytes\n",
    "input_state = {\n",
    "    \"uploaded_file_1\": uploaded_file_1,\n",
    "}\n",
    "\n",
    "# Execute the graph\n",
    "result = graph.invoke(input_state)\n",
    "# Access the extracted specifications\n",
    "specifications = result[\"specifications\"]\n",
    "pdf_text = result[\"pdf1_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_specs, additional_info = handle_incorrect_action(pdf_text, input_prompt)\n",
    "# print(filtered_specs)\n",
    "# print(additional_info)\n",
    "# print(spec_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(specifications)\n",
    "# data3 = json.loads(additional_info)\n",
    "# df3 = pd.DataFrame(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " print type of pdf_text :  <class 'list'>\n",
      "type of additional_info:  <class 'str'>\n",
      "Query rewrited and done a fresh search. Fetched additional information from the internet\n",
      "JSON data loaded successfully.\n",
      "Specifications not available in datasheet by fetched by the model\n",
      "               index                                    0\n",
      "0         Resolution   3840 x 2160 pixels (from internet)\n",
      "1       Refresh Rate               120 Hz (from internet)\n",
      "2        HDR Support                  Yes (from internet)\n",
      "3        Screen Size            55 inches (from internet)\n",
      "4       Audio Output                  20W (from internet)\n",
      "5         HDMI Ports                    4 (from internet)\n",
      "6          USB Ports                    3 (from internet)\n",
      "7          Bluetooth                  Yes (from internet)\n",
      "8              Wi-Fi                  Yes (from internet)\n",
      "9      Ethernet Port                  Yes (from internet)\n",
      "10            Weight              18.5 kg (from internet)\n",
      "11        Dimensions  1230 x 780 x 240 mm (from internet)\n",
      "12          Smart TV                  Yes (from internet)\n",
      "13  Operating System              Android (from internet)\n",
      "14         Processor            Quad-core (from internet)\n",
      "15               RAM                 2 GB (from internet)\n",
      "16           Storage                16 GB (from internet)\n",
      "17    Remote Control                  Yes (from internet)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\INBHV3\\AppData\\Local\\anaconda3\\envs\\langchain\\Lib\\site-packages\\xlsxwriter\\workbook.py:368: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "if specifications:\n",
    "    # print(\"Specifications extracted from the provided datasheet\")\n",
    "    # print(specifications)\n",
    "\n",
    "    print(\"\\n print type of pdf_text : \", type(pdf_text))\n",
    "\n",
    "    #.....START OF FUNCTION.....#\n",
    "    def feedback_loop(button_pressed, specifications, pdf_text):\n",
    "        \n",
    "        # Define edges for button actions\n",
    "        if button_pressed == \"Correct\":\n",
    "            filtered_specs = specifications\n",
    "            additional_info = None\n",
    "        elif button_pressed == \"Incorrect\":\n",
    "            # pdf_text = extract_text_from_pdf(uploaded_file_1)\n",
    "            filtered_specs, additional_info = handle_incorrect_action(pdf_text, input_prompt)\n",
    "            print(\"Query rewrited and done a fresh search. Fetched additional information from the internet\")\n",
    "        elif button_pressed == \"Incomplete\":\n",
    "            filtered_specs = specifications\n",
    "            additional_info = handle_incomplete_action(filtered_specs)\n",
    "            print(\"Additional information fetched from the internet\")\n",
    "        # else:\n",
    "        #     st.write(\"You haven't selected a button\")\n",
    "            # graph_builder.add_edge(\"display_output\", END)\n",
    "        # Close the edges based on consditional selections of the above three edges\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        if filtered_specs:\n",
    "            try:\n",
    "                data2 = json.loads(additional_info)\n",
    "\n",
    "                df1 = pd.DataFrame(filtered_specs)\n",
    "                df2 = pd.DataFrame(data2)\n",
    "\n",
    "                df1 = df1.transpose().reset_index()\n",
    "                df2 = df2.transpose().reset_index()\n",
    "\n",
    "                # Concatenate the DataFrames\n",
    "                combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "                combined_df.columns = ['Specification', 'Extracted Information']\n",
    "                print(\"JSON data loaded successfully.\")\n",
    "\n",
    "                # Convert DataFrame to Excel\n",
    "                output = BytesIO()\n",
    "                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:\n",
    "                    combined_df.to_excel(writer, index=False, sheet_name='comparison_results')\n",
    "                    writer.close()\n",
    "                excel_data = output.getvalue()\n",
    "                \n",
    "                \n",
    "                print(\"Specifications not available in datasheet by fetched by the model\")\n",
    "                print(df2)\n",
    "\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON: {e}\")\n",
    "        else:\n",
    "            print(\"spec_list is empty or None.\")\n",
    "    #.....END OF FUNCTION......#\n",
    "\n",
    "    # feedback_loop(\"Correct\", specifications, pdf_text)\n",
    "    feedback_loop(\"Incorrect\", specifications, pdf_text)\n",
    "    # feedback_loop(\"Incomplete\", specifications, pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame(filtered_specs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
